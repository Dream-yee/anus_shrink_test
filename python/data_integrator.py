import json
import os
from typing import Dict, List, Any, Optional
import re

# --- è¨­å®šå¸¸æ•¸ (ä¿æŒä¸è®Š) ---
DATA_DIR = 'datas'
CURRENT_YEAR = 115
TARGET_START_YEAR = 112 
OUTPUT_FILE = 'datas/historical_result.json'

# --- è¼”åŠ©å‡½æ•¸ (ä¿æŒä¸è®Š) ---
def load_json_file(filepath: str) -> Dict:
    """è¼‰å…¥ JSON æª”æ¡ˆï¼Œå¦‚æœæª”æ¡ˆä¸å­˜åœ¨å‰‡è¿”å›ç©ºå­—å…¸ã€‚"""
    if not os.path.exists(filepath):
        # print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {filepath}ï¼Œè¦–ç‚ºç„¡è³‡æ–™ã€‚") # é—œé–‰è­¦å‘Šé¿å…è¼¸å‡ºéå¤š
        return {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼šæª”æ¡ˆ {filepath} æ ¼å¼éŒ¯èª¤ã€‚")
        return {}
# -----------------------------

def get_department_sort_key(dept_name: str) -> float:
    """
    ç‚ºæ ¡ç³»åç¨±ç”Ÿæˆä¸€å€‹æ’åºæ¬Šé‡ï¼Œç¢ºä¿ç”²ã€ä¹™ã€ä¸™çµ„ç­‰èƒ½æŒ‰é‚è¼¯é †åºæ’åˆ—ã€‚
    æ•¸å­—æ¬Šé‡è¶Šä½ï¼Œæ’åºè¶Šé å‰ã€‚
    """
    # é è¨­æ¬Šé‡ç‚ºé«˜ï¼Œç¢ºä¿æœªåŒ…å«é—œéµå­—çš„æ’åœ¨å¾Œé¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    base_weight = 1000.0

    # 1. å¤©å¹²åœ°æ”¯ (ç”² < ä¹™ < ä¸™...)
    # é€™è£¡è³¦äºˆæ•¸å­—æ¬Šé‡ï¼Œç¢ºä¿ç”²çµ„ (1) åœ¨ä¹™çµ„ (2) ä¹‹å‰
    mapping = {
        'ç”²': 1, 'ä¹™': 2, 'ä¸™': 3, 'ä¸': 4, 'æˆŠ': 5,
        'A': 1, 'B': 2, 'C': 3,
        'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, # é‡å°çµ„åˆ¥ç‚ºæ•¸å­—çš„æƒ…æ³ (å¦‚æœå­˜åœ¨)
    }

    # æª¢æŸ¥ä¸¦æ‡‰ç”¨æ¬Šé‡
    for char, weight in mapping.items():
        if char in dept_name:
            # æ‰¾åˆ°é—œéµå­—å¾Œï¼Œæ¬Šé‡è¶Šä½è¶Šé å‰
            return base_weight + weight # ç¢ºä¿æ‰€æœ‰çµ„åˆ¥éƒ½åœ¨åŸºç¤åç¨±ä¹‹å¾Œæ’åº

    # 2. è™•ç†æ•¸å­—çµ„åˆ¥ (ä¾‹å¦‚ çµ„1, çµ„2)
    match = re.search(r'çµ„(\d+)|ç­(\d+)', dept_name)
    if match:
        num = int(match.group(1) or match.group(2))
        return base_weight + num * 0.1
        
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•çµ„åˆ¥æ¨™è­˜ç¬¦ï¼Œå‰‡ä¿æŒåŸå§‹å­—ä¸²æ’åºï¼ˆä½œç‚ºæœ€å¾Œçš„ä¿éšªï¼‰
    return 1000

def integrate_data(start_year: int, end_year: int) -> Dict:
    """
    æ•´åˆå¤šå¹´åº¦çš„æ ¡ç³»æ•¸æ“šï¼Œä¿®å¾©åˆä½µæ¡ˆä¾‹è¿½æº¯ä¸å®Œæ•´çš„éŒ¯èª¤ï¼Œä¸¦ä½¿ç”¨ç·©å­˜é¿å…é‡è¤‡ IOã€‚
    
    :param start_year: æœ€æ—©çš„å¹´ä»½ (e.g., 112)
    :param end_year: æœ€æ–°çš„å¹´ä»½ (e.g., 115)
    :return: æ•´åˆå¾Œçš„ JSON çµæ§‹
    """
    
    # ----------------------------------------------------
    # I. æ•¸æ“šç·©å­˜èˆ‡åˆå§‹åŒ– (è§£æ±º IO æ€§èƒ½å•é¡Œ)
    # ----------------------------------------------------
    
    data_cache: Dict[str, Dict] = {}
    
    # è¼‰å…¥æ‰€æœ‰å¹´ä»½çš„æ­·å²æ•¸æ“š (result.json)
    for year in range(start_year, end_year): # e.g., 112, 113, 114
        path = os.path.join(DATA_DIR, str(year), 'result.json')
        data_cache[f'result_{year}'] = load_json_file(path)

    # è¼‰å…¥æ‰€æœ‰å¹´ä»½çš„æ”¹åæ˜ å°„ (dept_renamed.json)
    # é€™è£¡çš„æ˜ å°„æ˜¯ target_year çš„æ˜ å°„ï¼Œå®šç¾©äº† target_year-1 çš„èˆŠå -> target_year çš„æ–°å
    # æˆ‘å€‘éœ€è¦é€†å‘æ˜ å°„ï¼š æ–°å -> èˆŠååˆ—è¡¨
    reverse_maps: Dict[int, Dict[str, Dict[str, List[str]]]] = {} 
    
    for year in range(start_year + 1, end_year + 1): # e.g., 113, 114, 115
        path = os.path.join(DATA_DIR, str(year), 'dept_renamed.json')
        forward_map_for_year = load_json_file(path) # çµæ§‹: { å­¸æ ¡: { èˆŠå: [æ–°ååˆ—è¡¨] } }
        
        # å»ºç«‹é€†å‘æ˜ å°„: { å­¸æ ¡: { æ–°å: [èˆŠååˆ—è¡¨] } }
        reverse_maps[year] = {}
        
        for uni, forward_map_for_uni in forward_map_for_year.items():
            reverse_maps[year][uni] = {}
            for old_dept_name, new_dept_names in forward_map_for_uni.items():
                for new_dept_name in new_dept_names:
                    # å¦‚æœæ–°ç³»åæ˜¯ key, èˆŠç³»åæ˜¯ value
                    reverse_maps[year][uni].setdefault(new_dept_name, []).append(old_dept_name)

    # è¼‰å…¥æœ€æ–°ä¸€å¹´çš„æ•¸æ“š (115) ä½œç‚ºåŸºæº–
    current_data_path = os.path.join(DATA_DIR, str(end_year), 'all_department_criteria.json')
    integrated_data = load_json_file(current_data_path)
    
    final_integrated_data: Dict = {}
    
    # ----------------------------------------------------
    # II. æ ¸å¿ƒæ•¸æ“šè¿½æº¯ (ä¿®æ­£åˆä½µè¿½æº¯å•é¡Œ)
    # ----------------------------------------------------

    for uni, depts_115 in integrated_data.items():
        if uni not in final_integrated_data:
            final_integrated_data[uni] = {}
            
        for dept_115 in depts_115.keys():
            
            # åˆå§‹åŒ– 115 å¹´æ•¸æ“š
            final_integrated_data[uni][dept_115] = {str(end_year): depts_115[dept_115]}
            
            # current_dept_names å­˜å„²çš„æ˜¯ç›®æ¨™å¹´ä»½ (target_year) çš„ç³»ååˆ—è¡¨
            # æˆ‘å€‘å¾ end_year (115) çš„å–®å€‹ç³»åé–‹å§‹
            current_dept_names: List[str] = [dept_115]
            
            # è¿­ä»£å¹´ä»½: å¾ end_year (115) é–‹å§‹è¿½æº¯åˆ° start_year (112)
            # target_year è¡¨ç¤ºç•¶å‰è¿­ä»£ç›®æ¨™æ˜¯å“ªå€‹å¹´ä»½çš„æ˜ å°„
            for target_year in range(end_year, start_year, -1): # e.g., 115, 114, 113
                
                history_data_year = target_year - 1 # e.g., 114, 113, 112
                
                # ç²å–é€†å‘æ˜ å°„è¡¨: { æ–°å: [èˆŠååˆ—è¡¨] }
                reverse_map_for_uni = reverse_maps.get(target_year, {}).get(uni, {})
                
                # ç²å–æ­·å²æ•¸æ“šç·©å­˜
                history_data = data_cache.get(f'result_{history_data_year}', {})
                history_data_for_uni = history_data.get(uni, {})
                
                next_old_dept_names: List[str] = []
                history_records_for_current_dept: List[Dict] = []
                
                # è¿½æº¯æ‰€æœ‰å¯èƒ½çš„ "ç•¶å‰ç³»å" (current_dept_names) åœ¨æ­·å²æ•¸æ“šå¹´ (history_data_year) çš„"èˆŠç³»å"
                for dept_name_at_target_year in current_dept_names:
                    
                    # 1. æª¢æŸ¥æ˜¯å¦æœ‰æ˜ç¢ºçš„é€†å‘æ˜ å°„ (ä¾‹å¦‚ï¼š114ç”²çµ„+ä¹™çµ„ -> 115å­¸å£«ç­)
                    if dept_name_at_target_year in reverse_map_for_uni:
                        # æ‰¾åˆ°äº†å¤šå€‹èˆŠç³»å (ä¾‹å¦‚ï¼šç”²çµ„å’Œä¹™çµ„)
                        old_names = reverse_map_for_uni[dept_name_at_target_year]
                    else:
                        # å‡è¨­æ²’æœ‰æ”¹åæˆ–åˆä½µ
                        old_names = [dept_name_at_target_year] 
                    
                    
                    # 2. ç²å–é€™äº›èˆŠç³»ååœ¨æ­·å²å¹´ä»½çš„æ•¸æ“šï¼Œä¸¦æº–å‚™ä¸‹ä¸€è¼ªè¿½æº¯
                    for old_name in old_names:
                        
                        if old_name in history_data_for_uni:
                            # æ‰¾åˆ°æ­·å²æ•¸æ“šï¼ŒåŠ å…¥åˆ—è¡¨
                            history_item = history_data_for_uni[old_name].copy()
                            history_item["æ ¡ç³»åç¨±"] = old_name # è¨˜éŒ„ç•¶æ™‚çš„ç³»å
                            history_records_for_current_dept.append(history_item)
                            
                        # ç„¡è«–æ˜¯å¦æœ‰æ•¸æ“šï¼Œé€™å€‹èˆŠåéƒ½æœƒæˆç‚ºä¸‹ä¸€è¼ªè¿½æº¯çš„ç›®æ¨™
                        next_old_dept_names.append(old_name)

                
                # 3. å„²å­˜æ­·å²ç´€éŒ„åˆ° final_integrated_data
                if history_records_for_current_dept:
                    # ä½¿ç”¨è‡ªå®šç¾©å‡½æ•¸ä½œç‚º Key é€²è¡Œæ’åº
                    history_records_for_current_dept.sort(
                        key=lambda x: get_department_sort_key(x["æ ¡ç³»åç¨±"])
                    )
                    # æ­·å²ç´€éŒ„å¯èƒ½æœ‰å¤šç­† (ä¾‹å¦‚ï¼šç”²çµ„å’Œä¹™çµ„çš„æ•¸æ“š)
                    final_integrated_data[uni][dept_115][str(history_data_year)] = history_records_for_current_dept
                
                # 4. æº–å‚™ä¸‹ä¸€è¼ªè¿­ä»£ (å°‡æ‰€æœ‰æ‰¾åˆ°çš„èˆŠç³»åä½œç‚ºä¸‹ä¸€è¼ªè¦è¿½æº¯çš„ç›®æ¨™)
                # ç¢ºä¿åˆ—è¡¨æ˜¯å”¯ä¸€çš„
                current_dept_names = list(set(next_old_dept_names)) 
                
                # å¦‚æœæ‰¾ä¸åˆ°ä»»ä½•èˆŠç³»åï¼Œå‰‡åœæ­¢è¿½æº¯
                if not current_dept_names:
                    break

    return final_integrated_data


# =======================================================
# åŸ·è¡Œç¨‹å¼ç¢¼ (ä¿æŒä¸è®Š)
# =======================================================
if __name__ == "__main__":
    
    # ğŸ’¡ ç¢ºä¿æ‚¨åœ¨æ­¤è™•å–æ¶ˆè¨»é‡‹ä¸¦é‹è¡Œäº†æ¨¡æ“¬æ•¸æ“šï¼Œç‰¹åˆ¥æ˜¯ 114å¹´/113å¹´ çš„æ˜ å°„ï¼Œä»¥æ¸¬è©¦è¿½æº¯é‚è¼¯ã€‚
    
    final_result = integrate_data(TARGET_START_YEAR, CURRENT_YEAR)

    # å¯«å…¥æœ€çµ‚çµæœ
    # ç¢ºä¿ datas è³‡æ–™å¤¾å­˜åœ¨ï¼Œå¦å‰‡æœƒå ±éŒ¯
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True) 
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, ensure_ascii=False, indent=4)
    
    print(f"\nâœ… æ•¸æ“šæ•´åˆå®Œæˆï¼çµæœå·²å„²å­˜è‡³ {OUTPUT_FILE}")