import json
import os
from typing import Dict, List, Any, Optional

# --- è¨­å®šå¸¸æ•¸ ---
DATA_DIR = 'datas'
CURRENT_YEAR = 115
TARGET_START_YEAR = 112 # è¿½æº¯åˆ°çš„æœ€æ—©å¹´ä»½ (ä¾‹å¦‚ï¼š115, 114, 113, 112)
OUTPUT_FILE = 'datas/historical_result.json'

# --- æ•¸æ“šæª”æ¡ˆè·¯å¾‘ ---
CURRENT_DATA_FILE = os.path.join(DATA_DIR, str(CURRENT_YEAR), 'all_department_criteria.json')
# æ­·å¹´æ•¸æ“šæª”æ¡ˆæ ¼å¼: data/114/result.json
# æ­·å¹´æ”¹åæ˜ å°„æª”æ¡ˆæ ¼å¼: data/114/dept_renamed.json (æ­¤æª”æ¡ˆå®šç¾©äº† 114å¹´çš„æ–°ç³»å <- 113å¹´çš„èˆŠç³»å)


def load_json_file(filepath: str) -> Dict:
    """è¼‰å…¥ JSON æª”æ¡ˆï¼Œå¦‚æœæª”æ¡ˆä¸å­˜åœ¨å‰‡è¿”å›ç©ºå­—å…¸ã€‚"""
    if not os.path.exists(filepath):
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {filepath}ï¼Œè¦–ç‚ºç„¡è³‡æ–™ã€‚")
        return {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼šæª”æ¡ˆ {filepath} æ ¼å¼éŒ¯èª¤ã€‚")
        return {}

def integrate_data(start_year: int, end_year: int) -> Dict:
    """
    æ•´åˆå¤šå¹´åº¦çš„æ ¡ç³»æ•¸æ“šï¼Œä»¥æœ€æ–°å¹´åº¦ (end_year) çš„ç³»åç‚ºåŸºæº–é€²è¡Œè¿½æº¯ã€‚
    
    :param start_year: æœ€æ—©çš„å¹´ä»½ (e.g., 112)
    :param end_year: æœ€æ–°çš„å¹´ä»½ (e.g., 115)
    :return: æ•´åˆå¾Œçš„ JSON çµæ§‹
    """
    
    # 1. è¼‰å…¥æœ€æ–°ä¸€å¹´çš„æ•¸æ“š (115)
    integrated_data = load_json_file(CURRENT_DATA_FILE)

    # 2. å»ºç«‹æ‰€æœ‰å¹´ä»½çš„ã€ŒèˆŠç³»å -> æ–°ç³»åã€æ­£å‘è¿½æº¯æ˜ å°„
    #    [115] å®šç¾© 114å¹´çš„èˆŠç³»å -> 115å¹´çš„æ–°ç³»å
    #    [114] å®šç¾© 113å¹´çš„èˆŠç³»å -> 114å¹´çš„æ–°ç³»å
    forward_maps: Dict[int, Dict[str, Dict[str, List[str]]]] = {}
    for year in range(end_year, start_year, -1):
        # è¼‰å…¥ data/115/dept_renamed.json (å®ƒå®šç¾©äº† 114å¹´èˆŠç³»å -> 115å¹´æ–°ç³»å)
        renamed_file = os.path.join(DATA_DIR, str(year), 'dept_renamed.json')
        forward_maps[year] = load_json_file(renamed_file) # çµæ§‹: { å­¸æ ¡: { èˆŠç³»å: [æ–°ç³»ååˆ—è¡¨] } }

    # 3. å¾æœ€æ–°å¹´åº¦é–‹å§‹ï¼Œè¿­ä»£æ¯å€‹å­¸æ ¡å’Œç§‘ç³»ï¼Œä¸¦é€²è¡Œæ­·å²æ•¸æ“šè¿½æº¯
    
    # è¿½æº¯éç¨‹éœ€è¦ä¸€å€‹ç¸½é«”é›†åˆä¾†è¿½è¹¤å“ªäº›èˆŠç³»åå·²ç¶“è¢«å½™æ•´é
    # çµæ§‹: { 'åœ‹ç«‹è‡ºç£å¤§å­¸': { 'ä¸­åœ‹æ–‡å­¸ç³»': True, ... } }
    processed_old_depts: Dict[str, Dict[str, bool]] = {}

    final_integrated_data: Dict = {}

    # åˆå§‹åŒ– final_integrated_data çš„çµæ§‹
    for uni, depts in integrated_data.items():
        if uni not in final_integrated_data:
            final_integrated_data[uni] = {}
        for dept in depts.keys():
             final_integrated_data[uni][dept] = {str(end_year): depts[dept]}
             processed_old_depts.setdefault(uni, {})

    for uni in integrated_data.keys():
        for dept_115 in integrated_data[uni].keys():
            
            # å¾æœ€æ–°å¹´ (end_year) çš„ç³»åé–‹å§‹è¿½æº¯
            current_old_dept_name = dept_115 # é€™ä¸€è¼ªè¦æ‰¾çš„ã€ŒèˆŠç³»åã€åœ¨ history_data_year çš„åç¨±
            
            # è¿­ä»£å¹´ä»½: 115 æ‰¾ 114 çš„æ•¸æ“šï¼Œ114 æ‰¾ 113 çš„æ•¸æ“š
            for target_year in range(end_year, start_year - 1, -1):
                
                history_data_year = target_year - 1
                if history_data_year < start_year:
                    break
                
                # è¼‰å…¥ç•¶å¹´çš„æ­·å¹´æ•¸æ“š
                history_data_path = os.path.join(DATA_DIR, str(history_data_year), 'result.json')
                history_data = load_json_file(history_data_path)
                
                # ç²å–è¿½æº¯æ˜ å°„ (ä¾‹å¦‚ï¼štarget_year=115ï¼Œæˆ‘å€‘ä½¿ç”¨ 115 çš„æ˜ å°„ä¾†æ‰¾ 114 å¹´çš„èˆŠç³»å)
                # target_map çµæ§‹: { èˆŠç³»å: [æ–°ç³»ååˆ—è¡¨] }
                # é€™è£¡çš„ target_map å®šç¾©äº† history_data_year çš„èˆŠç³»åæœƒè®Šæˆä»€éº¼
                forward_map_for_uni = forward_maps.get(target_year, {}).get(uni, {})
                
                
                # --- æ ¸å¿ƒæŸ¥æ‰¾é‚è¼¯ ---
                
                # 1. æ‰¾å‡º history_data_year ä¸­ï¼Œ**åç¨±**ç‚º current_old_dept_name çš„ç³»ï¼Œ
                #    å®ƒåœ¨ history_data_year-1 å¹´æ˜¯ä»€éº¼åå­— (old_dept_names_in_history)ã€‚
                
                # é€™è£¡æˆ‘å€‘éœ€è¦åˆ¤æ–· history_data_year çš„å“ªå€‹ç³»å (history_dept_name) 
                # æ˜¯ç”± history_data_year-1 çš„å“ªå€‹ç³»åè®Šéä¾†çš„ã€‚
                
                
                # 2. **æ›´ç°¡å–®çš„é‚è¼¯**ï¼šæˆ‘å€‘åªéœ€è¦çŸ¥é“ current_old_dept_name åœ¨ history_data_year-1 å¹´çš„åç¨±æ˜¯ä»€éº¼ã€‚
                #    ä½†å› ç‚ºæ‚¨çš„çµæ§‹æ˜¯ä»¥ 115 å¹´çš„ç³»åç‚ºåŸºæº–ï¼Œæˆ‘å€‘åªéœ€è¦æª¢æŸ¥ history_data_year çš„ç³»åæ˜¯å¦åŒ…å«åœ¨ 115 å¹´çš„åˆ—è¡¨è£¡ã€‚
                
                
                # ğŸŒŸ é‡æ–°å®šç¾©è¿½æº¯é‚è¼¯ ğŸŒŸ
                # æˆ‘å€‘è¦æ‰¾çš„æ˜¯ history_data_year çš„å“ªå€‹ç³»å(key) è®Šæˆäº† current_old_dept_name (åœ¨ target_year)
                
                
                # æ‰¾å‡ºæ‰€æœ‰åœ¨ history_data_year ä¸­ï¼Œå…¶æ–°ç³»ååŒ…å«åœ¨ current_old_dept_name è¿½æº¯éˆä¸Šçš„ "èˆŠç³»å"
                old_dept_names_to_lookup: List[str] = []
                
                # éæ­·æ­·å²æ•¸æ“šå¹´ä»½ (history_data_year) çš„ç³»å (old_dept_name)
                for old_dept_name, new_dept_names in forward_map_for_uni.items():
                    # æª¢æŸ¥é€™å€‹èˆŠç³»å (old_dept_name) è®Šæˆçš„ "æ–°ç³»å" åˆ—è¡¨
                    # æ˜¯å¦åŒ…å«æˆ‘å€‘ç›®å‰æ­£åœ¨è¿½æº¯çš„ç³»å (current_old_dept_name)
                    if current_old_dept_name in new_dept_names:
                        old_dept_names_to_lookup.append(old_dept_name)
                        
                # å¦‚æœæ‰¾ä¸åˆ°æ˜ å°„ï¼Œå‡è¨­åç¨±æ²’æœ‰è®Šå‹•
                if not old_dept_names_to_lookup:
                    old_dept_names_to_lookup = [current_old_dept_name] 

                # --- ç²å–ä¸¦å„²å­˜æ­·å²æ•¸æ“š ---
                history_list: List[Dict] = []

                for dept_name_in_history in old_dept_names_to_lookup:
                    
                    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
                    if processed_old_depts[uni].get(dept_name_in_history) == history_data_year:
                        continue
                    
                    if dept_name_in_history in history_data.get(uni, {}):
                        history_item = history_data[uni][dept_name_in_history].copy()
                        history_item["æ ¡ç³»åç¨±"] = dept_name_in_history
                        history_list.append(history_item)
                        processed_old_depts[uni][dept_name_in_history] = history_data_year

                if history_list:
                    final_integrated_data[uni][dept_115][str(history_data_year)] = history_list
                
                # --- æº–å‚™ä¸‹ä¸€è¼ªè¿½æº¯ (DFS) ---
                
                # å¦‚æœæ˜¯å¤šå°ä¸€ (åˆä½µ) æˆ–ä¸€å°ä¸€ (æ”¹å)ï¼Œä¸‹ä¸€è¼ªçš„è¿½æº¯åç¨±æ˜¯åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹åç¨±ã€‚
                if old_dept_names_to_lookup:
                    current_old_dept_name = old_dept_names_to_lookup[0]
                # å¦‚æœæ˜¯ä»Šå¹´ç³»åæ²’æœ‰è®Šå‹•çš„æƒ…æ³ï¼Œcurrent_old_dept_name ä¿æŒä¸è®Šã€‚

    return final_integrated_data


# =======================================================
# åŸ·è¡Œç¨‹å¼ç¢¼
# =======================================================
if __name__ == "__main__":
    
    # ğŸ’¡ æ¨¡æ“¬è³‡æ–™å¤¾çµæ§‹å’Œæª”æ¡ˆå…§å®¹ (ç¢ºä¿ç¨‹å¼ç¢¼å¯ä»¥é‹è¡Œå’Œé©—è­‰é‚è¼¯)
    
    # # å‰µå»ºè³‡æ–™å¤¾
    # for year in range(TARGET_START_YEAR, CURRENT_YEAR + 1):
    #     os.makedirs(os.path.join(DATA_DIR, str(year)), exist_ok=True)
    
    # # --- 115 å¹´æ•¸æ“š (æœ€æ–°å¹´ï¼Œä½œç‚ºåŸºæº–) ---
    # data_115 = {
    #     "åœ‹ç«‹è‡ºç£å¤§å­¸": {
    #         "ä¸­åœ‹æ–‡å­¸ç³»": {"æ ¸å®šäººæ•¸": 20, "å­¸æ¸¬æ¨™æº–": {"æ•¸A": "å‡æ¨™"}, "ç§‘ç›®å€æ•¸": {"åœ‹æ–‡": 1.5}},
    #         "å¤–åœ‹èªæ–‡å­¸ç³»": {"æ ¸å®šäººæ•¸": 48, "å­¸æ¸¬æ¨™æº–": {"è‹±è½": "Aç´š"}, "ç§‘ç›®å€æ•¸": {"è‹±æ–‡": 2.0}},
    #     },
    #     "åœ‹ç«‹æ¸…è¯å¤§å­¸": {
    #          "é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­": {"æ ¸å®šäººæ•¸": 100, "å­¸æ¸¬æ¨™æº–": {"æ•¸A": "é ‚æ¨™"}, "ç§‘ç›®å€æ•¸": {"æ•¸ç”²": 1.5}} # 114å¹´æ˜¯ç”²ä¹™çµ„åˆä½µ
    #     }
    # }
    # with open(CURRENT_DATA_FILE, 'w', encoding='utf-8') as f:
    #     json.dump(data_115, f, ensure_ascii=False, indent=4)
        
    # # --- 115å¹´/114å¹´çš„æ”¹åæ˜ å°„ (å®šç¾© 115 <- 114 é—œä¿‚) ---
    # renamed_115 = {
    #     "åœ‹ç«‹æ¸…è¯å¤§å­¸": {
    #         "é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­": ["é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­ç”²çµ„", "é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­ä¹™çµ„"] # åˆä½µæ¡ˆä¾‹
    #     },
    #     "åœ‹ç«‹è‡ºç£å¤§å­¸": {
    #         "ä¸­åœ‹æ–‡å­¸ç³»": ["ä¸­åœ‹æ–‡å­¸ç³»"] # æ²’æ”¹åï¼Œä½†å¯«å…¥æ˜ å°„
    #     }
    # }
    # with open(os.path.join(DATA_DIR, '115', 'dept_renamed.json'), 'w', encoding='utf-8') as f:
    #     json.dump(renamed_115, f, ensure_ascii=False, indent=4)


    # # --- 114 å¹´æ•¸æ“š (æ­·å²æ•¸æ“š) ---
    # data_114 = {
    #     "åœ‹ç«‹è‡ºç£å¤§å­¸": {
    #         "ä¸­åœ‹æ–‡å­¸ç³»": {"ç§‘ç›®å€æ•¸": {"åœ‹æ–‡": 1.5}, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 52.8, "é”æ¨™æ¯”ä¾‹": 2.82}, # 114 å¹´å
    #         "å¤–åœ‹èªæ–‡å­¸ç³»": {"ç§‘ç›®å€æ•¸": {"è‹±æ–‡": 2.0}, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 52.12, "é”æ¨™æ¯”ä¾‹": 3.8},
    #     },
    #     "åœ‹ç«‹æ¸…è¯å¤§å­¸": {
    #         "é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­ç”²çµ„": {"ç§‘ç›®å€æ•¸": {"æ•¸ç”²": 1.5}, "éŒ„å–äººæ•¸": 60, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 65.0}, 
    #         "é›»æ©Ÿè³‡è¨Šå­¸é™¢å­¸å£«ç­ä¹™çµ„": {"ç§‘ç›®å€æ•¸": {"æ•¸ç”²": 1.5}, "éŒ„å–äººæ•¸": 40, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 60.0},
    #     }
    # }
    # with open(os.path.join(DATA_DIR, '114', 'result.json'), 'w', encoding='utf-8') as f:
    #     json.dump(data_114, f, ensure_ascii=False, indent=4)


    # # --- 114å¹´/113å¹´çš„æ”¹åæ˜ å°„ (å®šç¾© 114 <- 113 é—œä¿‚) ---
    # renamed_114 = {
    #     "åœ‹ç«‹è‡ºç£å¤§å­¸": {
    #          "ä¸­åœ‹æ–‡å­¸ç³»": ["åœ‹æ–‡ç³»"] # æ¨¡æ“¬æ”¹åï¼š114å¹´å«ä¸­åœ‹æ–‡å­¸ç³» <- 113å¹´å«åœ‹æ–‡ç³»
    #     }
    # }
    # with open(os.path.join(DATA_DIR, '114', 'dept_renamed.json'), 'w', encoding='utf-8') as f:
    #     json.dump(renamed_114, f, ensure_ascii=False, indent=4)
        
        
    # # --- 113 å¹´æ•¸æ“š (æ­·å²æ•¸æ“š) ---
    # data_113 = {
    #     "åœ‹ç«‹è‡ºç£å¤§å­¸": {
    #         "åœ‹æ–‡ç³»": {"ç§‘ç›®å€æ•¸": {"åœ‹æ–‡": 1.5}, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 51.8, "é”æ¨™æ¯”ä¾‹": 4.64}, # 113 å¹´å
    #         "å¤–åœ‹èªæ–‡å­¸ç³»": {"ç§‘ç›®å€æ•¸": {"è‹±æ–‡": 2.0}, "ä¸€èˆ¬è€ƒç”ŸéŒ„å–æ¨™æº–": 50.0, "é”æ¨™æ¯”ä¾‹": 4.0},
    #     }
    # }
    # with open(os.path.join(DATA_DIR, '113', 'result.json'), 'w', encoding='utf-8') as f:
    #     json.dump(data_113, f, ensure_ascii=False, indent=4)

    # åŸ·è¡Œæ•´åˆ
    final_result = integrate_data(TARGET_START_YEAR, CURRENT_YEAR)

    # å¯«å…¥æœ€çµ‚çµæœ
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, ensure_ascii=False, indent=4)
    
    print(f"\nâœ… æ•¸æ“šæ•´åˆå®Œæˆï¼çµæœå·²å„²å­˜è‡³ {OUTPUT_FILE}")